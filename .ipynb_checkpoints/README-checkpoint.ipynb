{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ⓒ JMC 2017\n",
    "\n",
    "**SOURCE**  \n",
    "\\- 텐서플로로 시작하는 딥러닝, 나카이 에츠지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. 반복숙달용 Summary Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-1. 데이터를 모델링하는 3단계\n",
    "\n",
    "1. 주어진 데이터를 기반으로 미지의 데이터를 예측하는 '**모델 방정식**'을 생각한다.\n",
    "2. 모델 방정식에 포함된 파라미터의 좋고 나쁨을 판단하는 '**오차 함수**'를 준비한다.\n",
    "3. 오차 함수를 최소화하는 '**최적의 파라미터값**'을 결정한다.\n",
    "\n",
    "### Q1-2. 모델의 뜻\n",
    "\n",
    "+ 데이터를 설명하는 방정식\n",
    "\n",
    "### Q1-3. 머신러닝에서 컴퓨터가 하는 역할 (=텐서플로의 주요 업무)\n",
    "\n",
    "+ **파라미터 최적화** : 오차 함수를 최소화하는 계산을 정해진 알고리즘을 이용해 자동으로 계산하는 것이 머신러닝에서 컴퓨터가 하는 역할이며, 텐서플로의 주요 업무다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-4. 분류 문제에서 모델링하는 3단계\n",
    "\n",
    "1. 두 class의 경계를 나타내는 '**직선 형태의 모델 방정식(linear classifier)**'을 생각한다.\n",
    "> **Note**: 단, linear classifier를 sigmoid 함수에 대입해서 두 '**class에 속할 확률값**'을 도출한다.\n",
    "2. linear classifier에 포함된 파라미터의 좋고 나쁨을 판단하는 '**오차 함수**'를 준비한다.\n",
    "3. 오차 함수를 최소화하는 '**최적의 파라미터값**'을 결정한다.\n",
    "\n",
    "> **Note:** `linear classifier`란 분류 문제에서 사용하는 직선 형태의 모델을 뜻한다. || linear classifier 방정식 : $f(x_1, x_2) = w_0 + w_1x_1 + w_2x_2 = 0$ || linear classifier로 계산된 score 값을 0부터 1까지의 값을 가지는 함수에 대입하면 `각 class에 속할 확률값`인 $P(x_1, x_2)$를 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-5. 신경망이 데이터 모델링 3단계에서 가지는 의미\n",
    "\n",
    "+ 데이터 모델링 1단계에서 데이터를 설명하는 모델은 사람이 생각해내야 한다.\n",
    "+ 데이터의 차원이 아주 높다면 사람의 뇌로는 상상조차 할 수 없다.\n",
    "+ 그런데 '**신경망**'은 '**하나의 단순한 수식이 아니라 여러 개의 수식을 조합한 함수**'를 사용해서 다양한 데이터에 대응할 수 있는 모델이라는 데에 의미가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1-6. 파라미터를 최적화하는 방법\n",
    "\n",
    "먼저 오차 함수는 파라미터에 대한 함수라는 것을 알아야 한다.\n",
    "파라미터가 포함된 모델의 방정식이 오차 함수에 들어가 있다.\n",
    "즉, **파라미터 값이 변경되면 오차 함수의 값도 변화하므로, 오차 함수는 파라미터에 대한 함수라고 볼 수 있다**.\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (1.1) \\ L = \\frac{1}{2}\\Sigma(y_i - t_i)^{2} $\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (1.2) \\ y_i = w_0 + w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4 = \\Sigma w_ix_i$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (1.3) \\ L(w_0, w_1, w_2, w_3, w_4) = \\frac{1}{2}\\Sigma(\\Sigma w_ix_i - t_i)^{2}$\n",
    "\n",
    "**오차 함수를 다변수 공간에 표현했을 때 함수값이 최소로 되는 최저점을 찾아야 한다**.\n",
    "이 최저점은 '**기울기 벡터가 0이 되는 곳**'을 뜻한다.\n",
    "기울기 벡터는 오차 함수를 각 parameter별로 편미분하면 구할 수 있다.\n",
    "따라서 오차 함수를 편미분해서 기울기 벡터를 구하고 기울기 벡터가 0이 되는 곳을 찾으면, 오차 함수의 최소값을 구할 수 있게 된다.\n",
    "\n",
    "**기울기 벡터의 크기가 0이 되는 곳까지 현재 위치의 기울기 벡터와 반대 방향으로 반복해서 내려간다**.\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (1.8) \\ W^{new} = W - \\alpha \\triangledown L(W)$\n",
    "+ $W$ : $(w_0, w_1, w_2, w_3, w_4)$의 현재 위치(=좌표)\n",
    "+ $- \\triangledown L(W)$ : 현재 위치 $W$에서의 기울기 벡터와 반대방향으로 간다\n",
    "+ $- \\alpha \\triangledown L(W)$ : 한 번 반대 방향으로 갈 때 $\\alpha$만큼 이동한다\n",
    "+ $W^{new}$ : 현재 위치에서 현재 위치에서의 기울기 벡터만큼 반대 방향으로 이동한 곳이 새로운 위치이다 (= 파라미터 갱신)\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (1.9) \\ \\triangledown L(W) = \\begin{pmatrix}\n",
    "\\frac{\\partial L}{\\partial w_0}(W) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial L}{\\partial w_4}(W)\n",
    "\\end{pmatrix}$\n",
    "\n",
    "이때 식 (1.8)에서 파라미터를 갱신할 때마다 그 점에서의 기울기 벡터 값을 식 (1.9)로 다시 계산한다는 점에 주의한다.\n",
    "이렇게 '**현재 파라미터의 값에 대해 기울기 벡터를 계산하고, 그 반대 방향으로 파라미터를 수정하는 알고리즘**'을 '**경사 하강법(gradient descent**)'이라고 한다.\n",
    "현실의 문제에서는 충분히 원점에 가까워졌을 때 계산을 중단하고, 그 시점의 값을 근사적인 최적해로 채택한다.\n",
    "파라미터를 갱신하는 계산은 당연히 컴퓨터를 이용해 자동화하며, 이 부분이 머신러닝이나 딥러닝에서 텐서플로의 역할에 해당한다.\n",
    "**training set의 양이 많은 경우 한 번에 모든 데이터를 이용해서 파라미터를 최적화하는 것이 아니라, 단계적으로 데이터를 투입해가면서 파라미터를 최적화해 가는 식의 테크닉도 필요하다**.\n",
    "\n",
    "그런데 **오차 함수의 그래프가 여러 곳에 local minima가 있다면** 기울기 벡터가 0이 되는 곳이 여러 군데 존재하게 된다.\n",
    "즉, 경사 하강법으로 global minimum에 도달하지 못할 수도 있다.\n",
    "이와 같은 문제에 대응하기 위해 **확률적 경사 하강법(SGD)이나 미니 배치(mini-batch) 같은 테크닉을 사용한다**.\n",
    "\n",
    "> **Note**: 2.3.4 미니배치와 확률적 경사 하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Summary Questions에 아직 등록되지 않은 Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 확률을 이용해서 모델을 만들면 생기는 이점\n",
    "\n",
    "+ 확률을 이용해서 모델을 만들면, 오차 함수로 자연스럽게 최우추정법(MLE)을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 로지스틱 회귀를 이용한 이항 분류기\n",
    "\n",
    "#### 데이터 모델링 1단계 : 모델 방정식 세우기 (1)\n",
    "\n",
    "두 가지 검사 $x_1, x_2$를 토대로 바이러스 감염, 비감염 판정을 내리는 training data가 있다.\n",
    "training data를 시각화하면 $x_1, x_2$축을 가진 그래프에서 감염(o), 비감염(x)을 나타내는 데이터 포인트가 찍힌다.\n",
    "우리의 목적은 데이터의 분류이므로 데이터 포인트 (o)와 (x)를 분리하는 직선을 그을 수 있다.\n",
    "두 데이터의 경계를 나타내는 이 직선을 linear classifier라고 한다.\n",
    "linear classifier는 분류 문제에서 데이터의 경계를 나눠서, 어떤 데이터가 어느 클래스에 속하는지 설명해주므로 '모델'이 된다.\n",
    "모델은 다음과 같이 수식으로 나타낼 수 있다.\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.1) \\ f(x_1, x_2) = w_0 + w_1x_1 + w_2x_2$\n",
    "\n",
    "#### 데이터 모델링 1단계 : 모델 방정식 세우기 (2)\n",
    "\n",
    "우리의 목표는 새로운 검사 결과 $(x_1, x_2)$가 나왔을 때 이 환자가 실제로 감염되었는지 판정하는 것이다.\n",
    "$x_1, x_2$축을 가진 그래프에 새로운 환자의 데이터가 찍혔다고 해보자.\n",
    "이를 단순하게 감염(o) 또는 비감염(x)으로 분류하는 것이 아니라 이 환자가 바이러스에 감염되었을 확률을 구하고자 한다.\n",
    "$f(x_1,x_2)$의 값은 $\\pm \\infty$를 향해 변화하므로 확률 값으로 적절하지 않다.\n",
    "$f(x_1,x_2)$의 범위를 확률의 범위 0~1 사이로 맞추기 위해 시그모이드 함수에 대입한다.\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.2) \\ -\\infty < f(x_1,x_2) < +\\infty$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.3) \\ 0 < \\sigma (x) = \\frac{1}{1 + e^{-x}} < 1$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.4) \\ 0 < \\sigma (f(x_1, x_2)) < 1 $\n",
    "\n",
    "결국 우리의 모델은 다음과 같이 표현된다.\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.5) \\ P(x_1, x_2) = \\sigma (f(x_1, x_2)) = \\frac{1}{1 + e^{-(w_0 + w_1x_1 + w_2x_2)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 모델링 2단계 : 오차 함수 준비 (1)\n",
    "\n",
    "\"확률을 이용해서 예측 모델을 만들면, 파라미터의 좋고 나쁨을 평가하는 오차 함수로 자연스럽게 최우추정법(MLE)를 사용할 수 있다는 이점이 있다.\"\n",
    "식 (2.5)에서 만든 모델에 포함된 파라미터의 좋고 나쁨을 어떻게 판단할 수 있을까?\n",
    "주어진 training data를 잘 맞히는지 알아보면 된다.\n",
    "엄밀히 말하자면, 수많은 parameter 조합 중에서 training data를 예측할 확률이 가장 높은 parameter를 선택하면 된다.\n",
    "이와 같이 주어진 데이터를 바르게 예측할 확률을 최대화하는 것을 최우추정법(Maximum Likelihood Estimation)이라고 한다.\n",
    "\n",
    "> **Note**: 모델 방정식에 포함된 parameter가 가질 수 있는 값은 무한 개이다. 즉, 가능한 모델의 개수 또한 무한 개이다. 최우추정법에서는 모델 여러 개 중에서 주어진 데이터를 예측할 확률이 가장 높은 모델을 선택하는 알고리즘이다.\n",
    "\n",
    "트레이닝 데이터 N개를 표현하면 식 (2.6)과 같다.\n",
    "$n$번째 데이터 $(x_{1_{n}}, x_{2_{n}})$의 바이러스 감염 여부를 $t_n \\in \\{0, 1\\} $이라고 하자. $n$번째 데이터를 바르게 예측할 확률을 $P_n$이라고 할 때 식 (2.7)과 식 (2.8)이 성립한다.\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.6) \\ (x_{1_{1}}, x_{2_{1}}), (x_{1_{2}}, x_{2_{2}}), \\cdot \\cdot \\cdot, (x_{1_{N}}, x_{2_{N}})$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.7) \\ [ \\begin{array}{ll} t_n=1 : P_n = P(x_{1_{n}}, x_{2_{n}}) \\\\\n",
    "t_n=0 : P_n = 1 - P(x_{1_{n}}, x_{2_{n}})\n",
    "\\end{array}$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.8) \\ P_n = \\{ P(x_{1_{n}}, x_{2_{n}}) \\}^{t_n} \\{ 1 - P(x_{1_{n}}, x_{2_{n}}) \\}^{1-t_n}$\n",
    "\n",
    "식 (2.8)의 이해를 돕기 위해 예를 들어보자. \n",
    "3번째 데이터 $(x_{1_{3}}, x_{2_{3}})$의 $t_3 = 1$이고, 모델의 예측값이 0.8이라고 해보자.\n",
    "$P_3 = P(x_{1_{3}}, x_{2_{3}}) = 0.8$이 된다.\n",
    "실제 데이터의 값 $t_n=1$일 때는 모델의 예측값이 1에 가까울수록 좋다.\n",
    "4번째 데이터 $(x_{1_{4}}, x_{2_{4}})$의 $t_n = 0$이고, 모델의 예측값이 0.3이라고 해보자.\n",
    "$P_4 = 1-P(x_{1_{4}}, x_{2_{4}}) = 1-0.3 = 0.7$이 된다.\n",
    "실제 데이터의 값 $t_n=0$일 때는 모델의 예측값이 0에 가까울수록 좋다.\n",
    "예를 통해서 두 가지를 알 수 있다. \n",
    "첫째, training data와 일치하는 모델일수록 $P_n$ 값이 1에 가까워지게 된다.\n",
    "둘째, $P_n$ 값의 범위는 $0 \\leq P_n \\leq 1$이 된다.\n",
    "\n",
    "$n$번째 데이터가 아니라 $N$개 데이터 모두 정답일 확률 $P$를 계산해보자.\n",
    "식 (2.9)에 나와 있듯이, 각 데이터를 바르게 예측할 확률의 곱셈으로 계산할 수 있다.\n",
    "식 (2.10)이 우리가 만든 모델 (2.5)의 우도 함수이자 오차 함수이다.\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.9) \\ P = P_1 \\times P_2 \\times \\cdots \\times P_N = \\Pi_{n=1}^{N}P_n$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.10) \\ P = \\Pi_{n=1}^{N}\\{ P(x_{1_{n}}, x_{2_{n}}) \\}^{t_n} \\{ 1 - P(x_{1_{n}}, x_{2_{n}}) \\}^{1-t_n}$\n",
    "\n",
    "$P_n$ 값의 범위가 $0 \\leq P_n \\leq 1$이므로 $P$의 범위 또한 $0 \\leq P \\leq 1$이 된다.\n",
    "\n",
    "#### 데이터 모델링 2단계 : 오차 함수 준비 (2)\n",
    "\n",
    "텐서플로로 계산할 경우 식 (2.10)과 같이 곱셈을 대량으로 포함하는 수식은 계산 효율이 좋지 않다.\n",
    "곱셉식을 덧셈으로 대체하려면 오차 함수에 $\\log$를 취하면 된다.\n",
    "따라서 $P$ 대신 $\\log P$로 나타낼 수 있다.\n",
    "$\\log$를 취하면 값의 범위가 아래 식처럼 변한다.\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.11) \\ 0 \\leq P \\leq 1$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.12) \\ -\\infty \\leq \\log P \\leq 0$ \n",
    "\n",
    "그런데 일반적으로 오차 함수가 내뱉는 값은 오차가 되어야 하고, 우리는 오차 함수의 값을 최소화하도록 판을 짜야 한다.\n",
    "그래서 $\\log P$에 마이너스를 취한다.\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.13) \\ 0 \\leq -\\log P \\leq \\infty$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.14) \\ L = - \\log P$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.15) \\ L = - \\log \\Pi_{n=1}^{N}\\{ P(x_{1_{n}}, x_{2_{n}}) \\}^{t_n} \\{ 1 - P(x_{1_{n}}, x_{2_{n}}) \\}^{1-t_n}$\n",
    "\n",
    "$ \\ \\ \\ \\ \\ (2.16) \\ L = - \\Sigma_{n=1}^{N} [t_n \\log P(x_{1_{n}}, x_{2_{n}}) + (1 - t_n) \\log \\{ 1 - P(x_{1_{n}}, x_{2_{n}}) \\}]$\n",
    "\n",
    "이렇게 해서 오차 함수가 식 (2.16)으로 완성되었다.\n",
    "\n",
    "> **Note**: 로그함수는 단조 증가하는 함수이므로 $P$를 최대로 하는 것과 $-\\log P$를 최소로 하는 것은 동치가 된다. 오차 함수를 통해 우리가 알고자 하는 것은 \"parameter $w$의 값이 어떻게 달라져야 오차가 적어지는지\"이다. 이를 구하는 방법은 parameter $w$를 하나 하나 변경하면서 오차를 관찰하는 방법과 오차 함수가 최저값이 될 때 parameter $w$는 어떤 값을 가지는지 관찰하는 방법이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
